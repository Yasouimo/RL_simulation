# ğŸ® Reinforcement Learning - GridWorld

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![NumPy](https://img.shields.io/badge/NumPy-1.24+-orange.svg)](https://numpy.org/)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-3.7+-green.svg)](https://matplotlib.org/)

> Comparaison de 4 algorithmes RL classiques sur un environnement GridWorld

---

## ğŸ“Š RÃ©sultats

| MÃ©thode | SuccÃ¨s | RÃ©compense | Vitesse |
|---------|--------|------------|---------|
| ğŸ¥‡ **Value Iteration** | 95% | +9.2 | â­â­â­â­â­ |
| ğŸ¥ˆ **Q-Learning ItÃ©ratif** | 70% | +6.3 | â­â­â­â­ |
| ğŸ¥‰ **Q-Learning Ã‰pisodique** | 55% | +4.5 | â­â­â­ |
| ğŸ’€ **Random (Baseline)** | 5% | -3.2 | â­ |

![Performance Comparison](https://via.placeholder.com/800x400/1a1a1a/00ff00?text=Performance+Chart+%7C+Value+Iteration+%3E+Q-Learning+Iterative+%3E+Q-Learning+Episodic+%3E+Random)

---

## ğŸ¯ L'Environnement

```
â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â”‚ ğŸ”´â”‚   â”‚   â”‚   â”‚   â”‚  ğŸ”´ Agent
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  ğŸŸ¡ Goal (dynamique)
â”‚   â”‚   â”‚ â¬›â”‚   â”‚   â”‚  â¬› Obstacle
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  
â”‚   â”‚   â”‚   â”‚   â”‚ ğŸŸ¡â”‚  RÃ©compenses:
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  +10 (goal)
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚  -0.01 (step)
â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜  -1 (obstacle)
```

**Grille 5Ã—5** Â· Goal repositionnÃ© chaque Ã©pisode Â· Max 100 steps

---

## ğŸš€ Quick Start

```bash
# Installation
pip install -r requirements.txt

# Value Iteration (meilleure performance)
cd "Value Iteration"
python main.py

# Q-Learning ItÃ©ratif (recommandÃ©)
cd Q-learning/iterative
python train_iterative.py

# Q-Learning Ã‰pisodique
cd Q-learning/episodic
python train_episodic.py

# Random Agent (baseline)
cd "Value Iteration Random"
python train_random.py

# Comparer Q-Learning
cd Q-learning
python compare_methods.py
```

---

## ğŸ“ Structure

```
RL_exo/
â”œâ”€â”€ Value Iteration/      # Planning (goal statique)
â”œâ”€â”€ Q-learning/
â”‚   â”œâ”€â”€ episodic/         # Updates fin d'Ã©pisode
â”‚   â”œâ”€â”€ iterative/        # Updates chaque step
â”‚   â””â”€â”€ compare_methods.py
â””â”€â”€ Value Iteration Random/  # Baseline
```

---

## ğŸ“Š Visualisation 4-Panel

![4-Panel Interface](https://via.placeholder.com/1200x800/2d2d2d/ffffff?text=GridWorld+%7C+Performance+Curves+%7C+Q-Table+Heatmap+%7C+Statistics)

Chaque mÃ©thode affiche en temps rÃ©el :
- ğŸ—ºï¸ **GridWorld** : Agent, goal, obstacles
- ğŸ“ˆ **Courbes** : RÃ©compenses et longueurs
- ğŸ”¥ **Heatmap** : Q-values ou values
- ğŸ“‹ **Stats** : Taux de succÃ¨s, epsilon, etc.

---

## ğŸ” DiffÃ©rences ClÃ©s

### Value Iteration vs Q-Learning

| | Value Iteration | Q-Learning |
|---|---|---|
| **Type** | Planning | Learning |
| **Goal** | Statique | Dynamique âœ¨ |
| **Performance** | 95% | 70% |

### Q-Learning : ItÃ©ratif vs Ã‰pisodique

| | ItÃ©ratif | Ã‰pisodique |
|---|---|---|
| **Updates** | Chaque step | Fin d'Ã©pisode |
| **SuccÃ¨s** | 70% | 55% |
| **Vitesse** | âš¡ Rapide | ğŸ¢ Lent |

![Learning Speed](https://via.placeholder.com/800x300/1a1a1a/ffaa00?text=Iterative+converges+2x+faster+than+Episodic)

---

## ğŸ’¡ Ce Qu'On Apprend

1. **Planning vs Learning** : Value Iteration gagne quand on connaÃ®t l'environnement
2. **Updates immÃ©diates** : ItÃ©ratif bat Ã‰pisodique (+30% succÃ¨s)
3. **Baseline importante** : Random (5%) prouve la valeur de l'apprentissage (+65%)

---

## ğŸ“ Concepts ImplÃ©mentÃ©s

âœ… Bellman Equation Â· Q-Learning Â· Epsilon-Greedy Â· State Augmentation Â· Heatmaps Â· Real-time Visualization

---

## ğŸ“š Documentation

- [`Value Iteration/README.md`](Value%20Iteration/README.md)
- [`Q-learning/README.md`](Q-learning/README.md)
- [`Value Iteration Random/README.md`](Value%20Iteration%20Random/README.md)

---

<div align="center">

**Technologies** : Python 3.8+ Â· NumPy Â· Matplotlib  
**Inspiration** : Sutton & Barto - "Reinforcement Learning: An Introduction"

![RL Logo](https://via.placeholder.com/600x200/4a90e2/ffffff?text=Reinforcement+Learning+GridWorld)

**â­ Comparez les 4 mÃ©thodes pour voir la puissance de l'apprentissage ! â­**

</div>
